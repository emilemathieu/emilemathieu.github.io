<!DOCTYPE HTML>
<!--
    Spatial by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
        <head>
        <title>An efficient soft-margin kernel SVM implementation in Python | Emile Mathieu - Blog</title>
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <meta name="description" content="Works" />
        <meta name="keywords" content="works,Emile Mathieu,Mathieu emile,emilemathieu" />
        <link rel="shortcut icon" href="Images/favicon.ico" type="image/vnd.microsoft.icon" />
        <!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
        <!--<script src="js/jquery.min.js"></script>
        <script src="js/skel.min.js"></script>
        <script src="js/skel-layers.min.js"></script>
        <script src="js/init.js"></script>
        -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/skel/2.2.1/skel.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/skel-layers/2.0.2/skel-layers.min.js"></script>
        <script src="js/init.js"></script>
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-90612705-1', 'auto');
          ga('send', 'pageview');
        </script>
        
        <noscript>
            <!-- <link rel="stylesheet" href="css/skel.css" /> -->
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/skel/2.2.1/skel.css" />
            <link rel="stylesheet" href="css/style.css" />
            <link rel="stylesheet" href="css/style-xlarge.css" />
            <link rel="stylesheet" href="https://assets-cdn.github.com/assets/gist-embed-9f0a4ad9c85ca776e669003688baa9d55f9db315562ce4d231d37dab2714c70a.css">
        </noscript>
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <!-- For offline development: -->
        <!--<script type="text/javascript" src="./MathJax-master/MathJax.js?config=TeX-AMS_HTML-full"></script>-->
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
        </script>
        <style type="text/css">
            canvas { border: 1px solid white; }
        </style>
        <meta property="og:title" content="An efficient soft-margin kernel SVM implementation in Python | Emile Mathieu - Blog" />
        <meta property="og:type" content="website" />
        <!-- <meta property="og:image" content="" /> -->
        <meta property="og:description" content="A simple tutorial to understand and build a soft-margin kernel SVM implementation in Python." />
    </head>
    <body class="landing">

          <!-- Header -->
            <header id="header" class="alt">
                <nav id="share" style="left: 1.25em;">
                    <ul class="icons">
                        <li style="margin-left:1em"><a href="https://github.com/emilemathieu" target="_blank" class="icon fa-github"><span class="label">Github</span></a></li>
                        <li style="margin-left:1em"><a href="https://fr.linkedin.com/in/emilemathieu" target="_blank" class="icon  fa-linkedin-square"><span class="label">Linkedin</span></a></li>
                    </ul>
                </nav>
                <!--<h1><strong><a href="index.html">Emile Mathieu</a></strong></h1>-->
                <nav id="nav">
                    <ul>
                        <li><a href="index.html">Home</a></li>
                        <!-- <li><a href="software.html">Software</a></li> -->
                        <li><a href="works.html">Works</a></li>
                        <li><a href="misc.html">Misc</a><li>
                        <li><strong><a href="blog.html">Blog</a></strong><li>
                        <li><a href="contact.html">Contact</a></li>
                    </ul>
                </nav>
            </header>

        <!-- Banner -->
            <section id="banner">
                <h2>Emile Mathieu</h2>
            </section>


        <!-- uncertainty -->
            <section id="uncertainty" class="wrapper">
                <div class="container blog" style="max-width: 800px;">

                    <header class="major special">
                        <h2>An efficient soft-margin kernel SVM implementation in Python</h2>
                        <p>August 5th, 2018</p>
                    </header>

                    <p>
                        <div class="social" style="text-align: center;">
                            <span class="twitter">
                                <a href="https://twitter.com/share" class="twitter-share-button"{count} data-url="http://emilemathieu.fr/blogpost1.html" data-size="default">Tweet</a>
                            </span>
                            <span class="google">
                                <div class="g-plusone" data-href="http://emilemathieu.fr/blogpost1.html"></div>
                            </span>
                            <span class="Facebook">
                                <div id="fb-root"></div>
                                <div class="fb-share-button" data-href="http://emilemathieu.fr/blogpost1.html" data-layout="button_count" style="height: 21px; width: 85px" allowTransparency="true"></div>
                            </span>
                        </div>
                    </p>

                    
                    <p style="display:none">
                    $
                    \newcommand{\R}{\mathbb{R}}
                    \newcommand{\N}{\mathcal{N}}
                    \newcommand{\svert}{~|~}
                    \newcommand{\f}{\mathbf{f}}
                    \newcommand{\x}{\mathbf{x}}
                    \newcommand{\y}{\mathbf{y}}
                    \newcommand{\z}{\mathbf{z}}
                    \newcommand{\w}{\mathbf{w}}
                    \newcommand{\W}{\mathbf{W}}
                    \newcommand{\ba}{\mathbf{a}}
                    \newcommand{\m}{\mathbf{m}}
                    \newcommand{\ls}{\mathbf{l}}
                    \newcommand{\bL}{\mathbf{L}}
                    \newcommand{\X}{\mathbf{X}}
                    \newcommand{\Y}{\mathbf{Y}}
                    \newcommand{\p}{\mathbf{p}}
                    \newcommand{\bepsilon}{\text{$\epsilon$}}
                    \newcommand{\bgamma}{\text{$\gamma$}}
                    \newcommand{\K}{\mathbf{K}}
                    \newcommand{\diag}{\text{diag}}
                    \newcommand{\argmin}{\text{argmin}}
                    $
                    </p>
                    <p>This short tutorial aims at introducing support vector machine (SVM) methods from its mathematical formulation along with an efficient implementation in a few lines of Python! The full code can be found on <a href="https://github.com/emilemathieu/ImageClassificationChallenge/tree/master/code/mllib/svm" target="_blank" >my github page</a>. I strongly recommend reading <a href="http://leon.bottou.org/publications/pdf/lin-2006.pdf" target="_blank" >Support Vector Machine Solvers</a> (from LÃ©on Bottou & Chih jen Lin) for an in-depth cover of the topic, along with the <a href="http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf" target="_blank" >LIBSVM</a> library (from Chih-Chung Chang & Chih-Jen Lin). The present post naturally follows this <a href="http://tullo.ch/articles/svm-py/" target="_blank" >introductory blog post on SVM</a>.</p>

                    <h2>The model: Support Vector Machines</h2>

                    <p>
                    <div><span class="image captioned right" style="max-width:250px"><img src="Images/blog/optimal-hyperplane.png" alt=""><h5>Figure 1: <i>An optimal hyperplane.</i></h5></span></div>
                    <a href="https://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" >Support vector machines</a> (SVMs) are supervised learning models for classification (or regression) which are defined by so-called <i>supporting hyperplanes</i>.
                    SVM is one of the most widely used algorithms since it relies on strong theoretical foundations and has good performance in practice.
                    </p>
                    <p>
                     SVMs represent examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.
                    <!-- This hyperplane is optimal in the sense that if the data is separable, it is the one with the maximum margin as shown on the Figure 1. -->
                    </p>
                    <p>
                    Let's consider our dataset to be
                    \begin{equation}
                    D = { (\mathbf{x}_{i}, y_{i}), \mathbf{x} \in \mathbb{R}^d, y \in \{ -1, 1 \}
                    }.
                    \end{equation}
                    and the mapping $\phi$, a (possibly) non-linear function used to get features from the datapoints.
                    <br>
                    The main idea is to find an hyperplane $\w$ separating our dataset and maximising the <i>margin</i> of this hyperplane. This is summed up in the optimisation problem below
                    \begin{equation} \label{eq:hard_objective}
                    \min _{\w, b} \mathcal{P}(\w, b) = \cfrac{1}{2} \w^2
                     \end{equation}
                     \begin{equation} \label{eq:hard_conditions}
                    \text{subject to} \  \forall i \ \ y_i(\w^T \phi(\x_i)+b) \ge 1
                    \end{equation}
                    The conditions (\ref{eq:hard_conditions}) enforce that datapoints (after being mapped through $\phi$) from the first (respectively second) category lie below (respectively above) the hyperplane $\w$, while the objective (\ref{eq:hard_objective}) measures the <i>margin</i>.
                    <br><br>
                    We implicitly made the assumption that the dataset $D$ was <i>separable</i> which means what it intuitively means; that there exists an hyperplane $\w \in \mathbb{R}^d$ such that all points $\{\x_i\}_i$ from the first category $\{-1\}$ lie on one side of the hyperplane (i.e. $\w^T \phi(\x_i)+b \le 1$) and  points $\{\x_i\}_i$ from the second category $\{+1\}$ lie on the other side of the hyperplane (i.e. $\w^T \phi(\x_i)+b \ge 1$).
                    This formulation is called <i>hard margin</i>, since the margin cannot let some datapoints <i>go through</i>.
                    This assumption can be relaxed by introducing penalty terms $\xi_i$ (and thus a penalty coefficient $C$) measuring the distance of $\x_i$ from the hyperplane $\w$ when $\x_i$ sits on the wrong side of the hyperplane.
                    This is formalised as the following constrained optimisation problem:
                    </p>

                    <!-- <h3>Kernel Trick</h3>
                    <p>Although SVMs are linear models, they can perform non-linear classification/regression using the so-called <i>kernel trick</i>, by implicitly mapping their inputs into high-dimensional feature spaces.</p> -->


                    <!-- <h3> Formulation </h3> -->

                    <p>
                    \begin{equation} \min _{\w, b, \mathbf{\xi}} \mathcal{P}(\w, b, \mathbf{\xi}) = \cfrac{1}{2} \w^2 + C \sum_{i=1}^n \xi_i \\
                    \text{subject to} \begin{cases} \forall i \quad y_i(\w^T \phi(\x_i)+b) \ge 1 - \xi_i \\ 
                    \forall i \quad \xi_i \ge 0 \end{cases}
                    \end{equation}

                    Seeing this problem as a <i>primal</i>, a <i>dual</i> optimisation problem can be derived (see <a href="http://leon.bottou.org/publications/pdf/lin-2006.pdf">L. Bottou et al</a> for more details):
                    \begin{equation} 
                    \max _{\alpha} \mathcal{D}(\alpha) = \sum_{i=1}^n \alpha_i - \cfrac{1}{2} \sum_{i,j=1}^n y_i \alpha_i y_j \alpha_j \mathbf{K}(\x_i, \x_j) \\
                    \text{subject to} \begin{cases} \forall i \quad 0 \le \alpha_i \le C \\ 
                    \sum_i y_i\alpha_i = 0 \end{cases}
                    \end{equation} 

                    with $\{\alpha_i\}_{i=1,\dots,n}$ being the dual coefficients and $\mathbf{K}$ being the kernel associated with $\phi$: $\forall i,j \ \ \mathbf{K}(\x_i, \x_j)=\left< \phi(\x_i) , \phi(\x_j)\right>$. 
                    </p>

                    From a Python's class point of view, an SVM model can be represented via the following attributes and methods:
                    <script src="https://gist.github.com/emilemathieu/c8873e7a3f1aca7d123bea7bc9305627.js"></script>


                    <!-- <code data-gist-id="https://gist.github.com/emilemathieu/c8873e7a3f1aca7d123bea7bc9305627.js"></code> -->

                    <h2>How to fit the model ?</h2>
                    <p>Once one have such an mathematical representation of the model through an optimisation problem, the next natural question which arise is: who should we solve this problem (once we know it is well-posed) ?
                    The SVM solution is the optimum of a well defined convex optimization problem introduced above.
                    Since the optimum does not depend on the way it has been calculated, the choice of a particular optimisation algorithm can be made on the sole basis of its computational requirements. The Python's method <i>_compute_weights</i> can therefore be implemented in several ways, and we'll present an efficient implementation.
                    <br><br>
                    The SVM optimisation problem can be cast as an Quadratic Problem (QP), a well studied class of optimisation problems for which  good libraries has been developed for.
                    This is the approach taken in this <a href="http://tullo.ch/articles/svm-py/">intro on SVM</a>, relying on the Python's quadratic program solver <a href="http://cvxopt.org">cvxopt</a>.
                    <br><br>
                    Yet this approach can be inefficient since such packages were often designed to take advantage of sparsity in the quadratic part of the objective function. Unfortunately, the SVM kernel matrix is rarely sparse but sparsity occurs in the <i>solution</i> of the SVM problem.
                    Moreover, the specification of a SVM problem rarely fits in memory and generic optimisation packages sometimes make extra work to locate the optimum with high accuracy which is often useless.
                    <br>
                    Let's then described an algorithm specifically tailored to solve the SVM optimisation problem.
                    </p>

                    <h3>The Sequential Minimal Optimization (SMO) algorithm</h3>

                    <script src="https://gist.github.com/emilemathieu/10f0b4a596c5ad571d8356f426b128a9.js"></script>

                    <!-- kernel trick; different kernels can be used such as the classic ones below -->
                    <!-- <script src="https://gist.github.com/emilemathieu/026df8545b880e7814ddc081a55a0e70.js"></script> -->


                    <!-- <h3>Demonstration</h3> -->



                    <h2>Discussion</h2>
                    <p>
                        <div class="social"">
                            <span class="twitter">
                                <a href="https://twitter.com/share" class="twitter-share-button"{count} data-url="http://emilemathieu.fr/blogpost1.html" data-size="default">Tweet</a>
                            </span>
                            <span class="google">
                                <div class="g-plusone" data-href="http://emilemathieu.fr/blogpost1.html"></div>
                            </span>
                            <span class="Facebook">
                                <div id="fb-root"></div>
                                <div class="fb-share-button" data-href="http://emilemathieu.fr/blogpost1.html" data-layout="button_count" style="height: 21px; width: 85px" allowTransparency="true"></div>
                            </span>
                        </div>
                    </p>

<!-- Share buttons UI -->
<style type="text/css">
/* This gets Google to fall into place */
.social {
    font-size: 1px;
    text-align: right;
}

/* This gets Facebook to fall into place */
.social iframe {
    vertical-align: middle;
}

/* Set an optional width for your button wrappers */
.social span {
    display: inline-block;
    /*width: 110px;*/
}

.social .twitter {
    margin-right: 6px;
}
.social .twitter a {
    margin-left: 5px;
    margin-top: 2px;
    color: #4e5665;
    font-size: 11px;
    line-height: 18px;
}
.social .google {
    width: 83px;
}
.social .Facebook {
    width: 85px;
}
.social .Facebook div span {
    vertical-align: middle !important;
}
</style>
<div id="fb-root"></div>
<script>(function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.3";
    fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<script src="https://apis.google.com/js/platform.js" async defer>
  {lang: 'en-GB'}
</script>

<script>window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  fjs.parentNode.insertBefore(js, fjs);
  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };
  return t;
}(document, "script", "twitter-wjs"));</script>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

var disqus_config = function () {
this.page.url = 'http://emilemathieu.fr';  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = 'svm'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://http-emilemathieu-fr.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>

    </body>
</html>